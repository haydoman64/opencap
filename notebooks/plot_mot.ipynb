{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader for .mot files\n",
    "\n",
    "def read_header(mot_file): \n",
    "    if not os.path.isfile(mot_file): \n",
    "        return []\n",
    "\n",
    "    try:         \n",
    "        with open(mot_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            headers = lines[10]\n",
    "            headers = headers.split()\n",
    "            return headers\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to load headers for file:{mot_file}. Error:{e}\")\n",
    "        return [] \n",
    "\n",
    "def storage_to_numpy(storage_file, excess_header_entries=0):\n",
    "    \"\"\"Returns the data from a storage file in a numpy format. Skips all lines\n",
    "    up to and including the line that says 'endheader'.\n",
    "    Parameters\n",
    "    ----------\n",
    "    storage_file : str\n",
    "        Path to an OpenSim Storage (.sto) file.\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray (or numpy structure array or something?)\n",
    "        Contains all columns from the storage file, indexable by column name.\n",
    "    excess_header_entries : int, optional\n",
    "        If the header row has more names in it than there are data columns.\n",
    "        We'll ignore this many header row entries from the end of the header\n",
    "        row. This argument allows for a hacky fix to an issue that arises from\n",
    "        Static Optimization '.sto' outputs.\n",
    "    Examples\n",
    "    --------\n",
    "    Columns from the storage file can be obtained as follows:\n",
    "        >>> data = storage2numpy('<filename>')\n",
    "        >>> data['ground_force_vy']\n",
    "    \"\"\"\n",
    "    # What's the line number of the line containing 'endheader'?\n",
    "    f = open(storage_file, 'r')\n",
    "\n",
    "    header_line = False\n",
    "    for i, line in enumerate(f):\n",
    "        if header_line:\n",
    "            column_names = line.split()\n",
    "            break\n",
    "        if line.count('endheader') != 0:\n",
    "            line_number_of_line_containing_endheader = i + 1\n",
    "            header_line = True\n",
    "    f.close()\n",
    "    # With this information, go get the data.\n",
    "    if excess_header_entries == 0:\n",
    "        names = True\n",
    "        skip_header = line_number_of_line_containing_endheader\n",
    "    else:\n",
    "        names = column_names[:-excess_header_entries]\n",
    "        skip_header = line_number_of_line_containing_endheader + 1\n",
    "    data = np.genfromtxt(storage_file, names=names,\n",
    "            skip_header=skip_header)\n",
    "\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_data.append(list(d))\n",
    "    new_data = np.array(new_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def storage_to_dataframe(storage_file, headers):\n",
    "    # Extract data\n",
    "    data = storage_to_numpy(storage_file)\n",
    "    data = np.array(data)\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_data.append(list(d))\n",
    "    new_data = np.array(new_data)\n",
    "    header_mapping = {header:i for i,header in enumerate(headers)}\n",
    "    out = pd.DataFrame(data=data['time'], columns=['time'])\n",
    "    for count, header in enumerate(headers):\n",
    "        out.insert(count + 1, header, new_data[:,count+1])    \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='/home/ubuntu/data/opencap-processing/Data/'\n",
    "\n",
    "def load_kinematics_data(mcs_sessions): \n",
    "    simulation_data = {}\n",
    "\n",
    "    for session_id in tqdm.tqdm(mcs_sessions): \n",
    "        simulation_results_path = os.path.join(base_dir, session_id, 'OpenSimData','Dynamics')\n",
    "        for trial in os.listdir(simulation_results_path): \n",
    "            \n",
    "            if trial == \"SQT01\": # Contains same results as segment-1 \n",
    "                continue\n",
    "\n",
    "            mot_file = os.path.join(simulation_results_path, trial, f'kinematics_activations_{trial}_torque_driven.mot')\n",
    "\n",
    "            if not os.path.isfile(mot_file): \n",
    "                print(f\"Simulation did not converge: \", session_id,trial)\n",
    "                continue \n",
    "            mot_headers = read_header(mot_file)\n",
    "            \n",
    "            if len(mot_headers) == 0:\n",
    "                print(f\"Unable to load headers for file:\", session_id,trial)\n",
    "                continue \n",
    "            \n",
    "            mot_headers = mot_headers\n",
    "            \n",
    "            # Remove time from headers\n",
    "            mot_headers.remove('time')\n",
    "            \n",
    "            mot_data = data = storage_to_dataframe(mot_file, headers = mot_headers)\n",
    "            \n",
    "            if session_id not in simulation_data: \n",
    "                simulation_data[session_id] = {}\n",
    "            \n",
    "            simulation_data[session_id][trial] = mot_data\n",
    "            print(mot_data.shape)\n",
    "            \n",
    "    return simulation_data \n",
    "\n",
    "\n",
    "# Load simulation for data for given list of sessions\n",
    "def load_simulation_data(mcs_sessions):\n",
    "    simulation_data = {}\n",
    "\n",
    "    for session_id in tqdm.tqdm(mcs_sessions): \n",
    "        simulation_results_path = os.path.join(base_dir, session_id, 'OpenSimData','Dynamics')\n",
    "        for trial in os.listdir(simulation_results_path): \n",
    "            \n",
    "            if trial == \"SQT01\": # Contains same results as segment-1 \n",
    "                continue\n",
    "\n",
    "            mot_file = os.path.join(simulation_results_path, trial, f'kinematics_activations_{trial}_torque_driven.mot')\n",
    "\n",
    "            if not os.path.isfile(mot_file): \n",
    "                print(f\"Simulation did not converge: \", session_id,trial)\n",
    "                continue \n",
    "            mot_headers = read_header(mot_file)\n",
    "            \n",
    "            if len(mot_headers) == 0:\n",
    "                print(f\"Unable to load headers for file:\", session_id,trial)\n",
    "                continue \n",
    "            \n",
    "            mot_headers = mot_headers\n",
    "            \n",
    "            # Remove time from headers\n",
    "            mot_headers.remove('time')\n",
    "            \n",
    "            mot_data = data = storage_to_dataframe(mot_file, headers = mot_headers)\n",
    "            \n",
    "            if session_id not in simulation_data: \n",
    "                simulation_data[session_id] = {}\n",
    "            \n",
    "            simulation_data[session_id][trial] = mot_data\n",
    "            print(mot_data.shape)\n",
    "            \n",
    "    return simulation_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2/21 [00:00<00:01, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 46)\n",
      "(31, 46)\n",
      "(133, 46)\n",
      "(191, 46)\n",
      "(132, 46)\n",
      "Simulation did not converge:  c613945f-1570-4011-93a4-8c8c6408e2cf SQT01_segment_3\n",
      "Simulation did not converge:  c613945f-1570-4011-93a4-8c8c6408e2cf SQT01_segment_1\n",
      "Simulation did not converge:  c613945f-1570-4011-93a4-8c8c6408e2cf SQT01_segment_2\n",
      "Simulation did not converge:  dfda5c67-a512-4ca2-a4b3-6a7e22599732 SQT01_segment_3\n",
      "Simulation did not converge:  dfda5c67-a512-4ca2-a4b3-6a7e22599732 SQT01_segment_1\n",
      "Simulation did not converge:  dfda5c67-a512-4ca2-a4b3-6a7e22599732 SQT01_segment_2\n",
      "(156, 46)\n",
      "(447, 46)\n",
      "(146, 46)\n",
      "(156, 46)\n",
      "(138, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 9/21 [00:00<00:00, 20.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 46)\n",
      "(163, 46)\n",
      "Simulation did not converge:  0e10a4e3-a93f-4b4d-9519-d9287d1d74eb SQT01_segment_1\n",
      "(157, 46)\n",
      "(141, 46)\n",
      "(162, 46)\n",
      "(139, 46)\n",
      "(165, 46)\n",
      "(603, 46)\n",
      "(157, 46)\n",
      "(127, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 13/21 [00:00<00:00, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 46)\n",
      "(143, 46)\n",
      "(108, 46)\n",
      "Simulation did not converge:  c28e768f-6e2b-4726-8919-c05b0af61e4a SQT01_segment_1\n",
      "(103, 46)\n",
      "Simulation did not converge:  fb6e8f87-a1cc-48b4-8217-4e8b160602bf SQT01_segment_3\n",
      "Simulation did not converge:  fb6e8f87-a1cc-48b4-8217-4e8b160602bf SQT01_segment_1\n",
      "Simulation did not converge:  fb6e8f87-a1cc-48b4-8217-4e8b160602bf SQT01_segment_2\n",
      "(130, 46)\n",
      "(225, 46)\n",
      "(122, 46)\n",
      "Simulation did not converge:  d66330dc-7884-4915-9dbb-0520932294c4 SQT01_segment_3\n",
      "(554, 46)\n",
      "(116, 46)\n",
      "Simulation did not converge:  0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45 SQT01_segment_3\n",
      "(422, 46)\n",
      "Simulation did not converge:  0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45 SQT01_segment_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 25.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 46)\n",
      "(229, 46)\n",
      "Simulation did not converge:  2345d831-6038-412e-84a9-971bc04da597 SQT01_segment_2\n",
      "Simulation did not converge:  0a959024-3371-478a-96da-bf17b1da15a9 SQT01_segment_3\n",
      "Simulation did not converge:  0a959024-3371-478a-96da-bf17b1da15a9 SQT01_segment_1\n",
      "Simulation did not converge:  0a959024-3371-478a-96da-bf17b1da15a9 SQT01_segment_2\n",
      "Simulation did not converge:  ef656fe8-27e7-428a-84a9-deb868da053d SQT01_segment_3\n",
      "Simulation did not converge:  ef656fe8-27e7-428a-84a9-deb868da053d SQT01_segment_1\n",
      "Simulation did not converge:  ef656fe8-27e7-428a-84a9-deb868da053d SQT01_segment_2\n",
      "(122, 46)\n",
      "Simulation did not converge:  c08f1d89-c843-4878-8406-b6f9798a558e SQT01_segment_1\n",
      "(124, 46)\n",
      "(197, 46)\n",
      "(241, 46)\n",
      "(150, 46)\n",
      "(112, 46)\n",
      "Simulation did not converge:  8dc21218-8338-4fd4-8164-f6f122dc33d9 SQT01_segment_1\n",
      "(115, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PPE Files containing with MCS Scores\n",
    "mcs_sessions = [\"349e4383-da38-4138-8371-9a5fed63a56a\",\"015b7571-9f0b-4db4-a854-68e57640640d\",\"c613945f-1570-4011-93a4-8c8c6408e2cf\",\"dfda5c67-a512-4ca2-a4b3-6a7e22599732\",\"7562e3c0-dea8-46f8-bc8b-ed9d0f002a77\",\"275561c0-5d50-4675-9df1-733390cd572f\",\"0e10a4e3-a93f-4b4d-9519-d9287d1d74eb\",\"a5e5d4cd-524c-4905-af85-99678e1239c8\",\"dd215900-9827-4ae6-a07d-543b8648b1da\",\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"c28e768f-6e2b-4726-8919-c05b0af61e4a\",\"fb6e8f87-a1cc-48b4-8217-4e8b160602bf\",\"e6b10bbf-4e00-4ac0-aade-68bc1447de3e\",\"d66330dc-7884-4915-9dbb-0520932294c4\",\"0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45\",\"2345d831-6038-412e-84a9-971bc04da597\",\"0a959024-3371-478a-96da-bf17b1da15a9\",\"ef656fe8-27e7-428a-84a9-deb868da053d\",\"c08f1d89-c843-4878-8406-b6f9798a558e\",\"d2020b0e-6d41-4759-87f0-5c158f6ab86a\",\"8dc21218-8338-4fd4-8164-f6f122dc33d9\"]\n",
    "\n",
    "mcs_scores = [4,4,2,3,2,4,3,3,2,3,0,3,4,2,2,3,4,4,3,3,3]\n",
    "mcs_scores = dict(zip(mcs_sessions,mcs_scores))\n",
    "\n",
    "simulation_data = load_simulation_data(mcs_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_box_plots(simulation_data, feature_names, features_per_fig=12):\n",
    "    num_features = len(feature_names)\n",
    "    num_figures = int(np.ceil(num_features / features_per_fig))  # Divide features into multiple figures\n",
    "\n",
    "    # Identify the minimum time length across all trials\n",
    "    min_time_length = np.inf\n",
    "    for session_id, trials in simulation_data.items():\n",
    "        for trial_id, df in trials.items():\n",
    "            min_time_length = min(min_time_length, len(df.index))  # Find the shortest time length\n",
    "\n",
    "    print(f\"Minimum time length across all trials: {min_time_length}\")\n",
    "\n",
    "    # Iterate through and create multiple figures\n",
    "    for fig_idx in range(num_figures):\n",
    "        start_idx = fig_idx * features_per_fig\n",
    "        end_idx = min(start_idx + features_per_fig, num_features)\n",
    "        features_to_plot = feature_names[start_idx:end_idx]\n",
    "\n",
    "        # Create subplots for the current figure\n",
    "        rows = int(np.ceil(len(features_to_plot) / 3))\n",
    "        fig = make_subplots(rows=rows, cols=3, subplot_titles=features_to_plot, vertical_spacing=0.1)\n",
    "\n",
    "        for i, feature in enumerate(features_to_plot):\n",
    "            row = i // 3 + 1\n",
    "            col = i % 3 + 1\n",
    "\n",
    "            feature_data = []\n",
    "            time_points = None\n",
    "            for session_id, trials in simulation_data.items():\n",
    "                for trial_id, df in trials.items():\n",
    "                    # Collect feature data for all subjects, trimming to min_time_length\n",
    "                    feature_data.append(df[feature].values[:min_time_length])\n",
    "                    time_points = df.index.values[:min_time_length]\n",
    "\n",
    "            # Convert the list of arrays into a 2D numpy array (T x num_trials)\n",
    "            feature_data = np.array(feature_data).T  # shape: T x num_trials\n",
    "\n",
    "            # Create box plot for each time point\n",
    "            for t, time_point in enumerate(time_points):\n",
    "                fig.add_trace(go.Box(\n",
    "                    y=feature_data[t],\n",
    "                    name=str(time_point),\n",
    "                    boxmean='sd',\n",
    "                    marker_color='gray',  # Monochrome color\n",
    "                    boxpoints = False # Hide outliers\n",
    "                ), row=row, col=col)\n",
    "\n",
    "        # Update layout for the figure\n",
    "        fig.update_layout(\n",
    "            height=300 * rows,  # Dynamically adjust height based on the number of rows\n",
    "            width=1000,\n",
    "            title_text=f\"Mean and Standard Deviation of Features Across Subjects (Features {start_idx+1}-{end_idx})\",\n",
    "            showlegend=False  # No legend\n",
    "        )\n",
    "\n",
    "        # Adjust x-axis labels\n",
    "        fig.update_xaxes(tickvals=time_points, ticktext=[str(t) for t in time_points])\n",
    "\n",
    "        # Show the current figure\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_trials = list(simulation_data.keys())\n",
    "trial_data = simulation_data[subject_trials[0]]  # Get first session for example\n",
    "feature_names = trial_data[list(trial_data.keys())[0]].columns[1:]  # Assuming 'time' is the first column\n",
    "\n",
    "# Call the box plot function\n",
    "plot_box_plots(simulation_data, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_simulation_data(trial_mot_data, mcs_scores): \n",
    "        \n",
    "    # Create 4x4 subplots (we'll only use 14 of them)\n",
    "    fig = make_subplots(rows=5, cols=3, subplot_titles=(\n",
    "        'Trunk Obliquity', 'Trunk Tilt', 'Trunk Rotation',\n",
    "        'Pelvic Obliquity', 'Pelvic Tilt', 'Pelvic Rotation',\n",
    "        'Left Hip Ab/Adduction', 'Left Hip Flexion/Extension', 'Left Hip Rotation',\n",
    "        'Right Hip Ab/Adduction', 'Right Hip Flexion/Extension', 'Right Hip Rotation',\n",
    "        'Left Knee Flexion/Extension', 'Right Knee Flexion/Extension',\n",
    "        'Ankle Dorsi/Plantar'\n",
    "    ))\n",
    "\n",
    "    # Define the mapping of DataFrame columns to plot titles\n",
    "    plot_mapping = {\n",
    "        'Trunk Obliquity': 'lumbar_bending',\n",
    "        'Trunk Tilt': 'lumbar_extension',\n",
    "        'Trunk Rotation': 'lumbar_rotation',\n",
    "        'Pelvic Obliquity': 'pelvis_list',\n",
    "        'Pelvic Tilt': 'pelvis_tilt',\n",
    "        'Pelvic Rotation': 'pelvis_rotation',\n",
    "        'Left Hip Ab/Adduction': 'hip_adduction_l',\n",
    "        'Left Hip Flexion/Extension': 'hip_flexion_l',\n",
    "        'Left Hip Rotation': 'hip_rotation_l',\n",
    "        'Right Hip Ab/Adduction': 'hip_adduction_r',\n",
    "        'Right Hip Flexion/Extension': 'hip_flexion_r',\n",
    "        'Right Hip Rotation': 'hip_rotation_r',\n",
    "        'Knee Varus/Valgus': ['knee_angle_l', 'knee_angle_r'],  # Assuming this corresponds to knee angle\n",
    "        'Knee Flexion/Extension': ['knee_angle_l', 'knee_angle_r'],\n",
    "        'Knee Rotation': ['knee_angle_l', 'knee_angle_r'],  # Assuming knee rotation is not directly available\n",
    "        'Ankle Dorsi/Plantar': ['ankle_angle_l', 'ankle_angle_r'],\n",
    "        'Foot Progress Angles': ['subtalar_angle_l', 'subtalar_angle_r']  # Assuming this corresponds to foot progress\n",
    "    }\n",
    "\n",
    "    # Colors for left and right sides\n",
    "    colors = {'left': 'blue', 'right': 'red'}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i, (title, columns) in enumerate(plot_mapping.items()):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "\n",
    "        for i,trial in enumerate(trial_mot_data):\n",
    "            df = trial_mot_data[trial]\n",
    "            \n",
    "            if isinstance(columns, list):\n",
    "                print(columns)\n",
    "                # Plot both left and right\n",
    "                fig.add_trace(go.Scatter(x=df['time']-df['time'][0], y=df[columns[0]], name=f'{i} {title} (Left)', line=dict(color=colors['left'])), row=row, col=col)\n",
    "                fig.add_trace(go.Scatter(x=df['time']-df['time'][0], y=df[columns[1]], name=f'{i} {title} (Right)', line=dict(color=colors['right'])), row=row, col=col)\n",
    "            else:\n",
    "                # Plot single trace\n",
    "                fig.add_trace(go.Scatter(x=df['time']-df['time'][0], y=df[columns], name=title), row=row, col=col)\n",
    "        \n",
    "        # Update y-axis label\n",
    "        fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "    # Update x-axis label for the bottom row\n",
    "    for col in range(1, 4):\n",
    "        fig.update_xaxes(title_text='%SQT Cycle', row=4, col=col)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=1200, width=1000, title_text=\"Biomechanical Model Kinematics\")\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for session_id in tqdm.tqdm(mcs_sessions):\n",
    "#     if session_id in simulation_data and session_id in mcs_scores and 0 < mcs_scores[session_id] < 5: \n",
    "#         plot_simulation_data(simulation_data[session_id], mcs_scores[session_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_simulation_data(session_id,trial_mot_data, mcs_score,subject_id): \n",
    "        \n",
    "    # Create 4x4 subplots (we'll only use 14 of them)\n",
    "    fig = make_subplots(rows=6, cols=3, subplot_titles=(\n",
    "        'Trunk Obliquity', 'Trunk Tilt', 'Trunk Rotation',\n",
    "        'Pelvic Obliquity', 'Pelvic Tilt', 'Pelvic Rotation',\n",
    "        'Left Hip Ab/Adduction', 'Left Hip Flexion/Extension', 'Left Hip Rotation',\n",
    "        'Right Hip Ab/Adduction', 'Right Hip Flexion/Extension', 'Right Hip Rotation',\n",
    "        'Left Knee Flexion/Extension', 'Right Knee Flexion/Extension', '',\n",
    "        'Left Ankle Dorsi/Plantar', 'Right Ankle Dorsi/Plantar', ''\n",
    "    ))\n",
    "\n",
    "    # Define the mapping of DataFrame columns to plot titles\n",
    "    plot_mapping = {\n",
    "        'Trunk Obliquity': 'lumbar_bending',\n",
    "        'Trunk Tilt': 'lumbar_extension',\n",
    "        'Trunk Rotation': 'lumbar_rotation',\n",
    "        'Pelvic Obliquity': 'pelvis_list',\n",
    "        'Pelvic Tilt': 'pelvis_tilt',\n",
    "        'Pelvic Rotation': 'pelvis_rotation',\n",
    "        'Left Hip Ab/Adduction': 'hip_adduction_l',\n",
    "        'Left Hip Flexion/Extension': 'hip_flexion_l',\n",
    "        'Left Hip Rotation': 'hip_rotation_l',\n",
    "        'Right Hip Ab/Adduction': 'hip_adduction_r',\n",
    "        'Right Hip Flexion/Extension': 'hip_flexion_r',\n",
    "        'Right Hip Rotation': 'hip_rotation_r',\n",
    "        'Left Knee Flexion/Extension': 'knee_angle_l',\n",
    "        'Right Knee Flexion/Extension': 'knee_angle_r',\n",
    "        'Knee Flexion/Extension': '',\n",
    "        'Left Ankle Dorsi/Plantar': 'ankle_angle_l',\n",
    "        'Right Ankle Dorsi/Plantar': 'ankle_angle_r', \n",
    "        'Ankle Dorsi/Plantar': '',\n",
    "    }\n",
    "\n",
    "    # Colors for left and right sides\n",
    "    colors = {'left': 'blue', 'right': 'red'}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i, (title, columns) in enumerate(plot_mapping.items()):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "\n",
    "        if columns == '': \n",
    "            continue  \n",
    "\n",
    "        for trial_id,trial in enumerate(trial_mot_data):\n",
    "            df = trial_mot_data[trial]\n",
    "            \n",
    "            # Plot single trace\n",
    "            fig.add_trace(go.Scatter(x=np.linspace(0,1,num=101), y=np.array(df[columns]), name=f'{trial_id} {title}'), row=row, col=col)\n",
    "    \n",
    "        # Update y-axis label\n",
    "        fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "    # Update x-axis label for the bottom row\n",
    "    for col in range(1, 6):\n",
    "        for row in range(1,6):\n",
    "            fig.update_xaxes(title_text='% SQT Cycle (Seconds)', row=row, col=col)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=1500, width=1000,\n",
    "                        showlegend=False,  title_x=0.5,\n",
    "                        title_text=f\"OpenCap Simulation Kinematics <br> Subject:{subject_id} MCS Score:{mcs_score}\",\n",
    "                        font_family=\"Times New Roman\",\n",
    "                        font_color=\"black\",\n",
    "                        title_font_family=\"Times New Roman\",\n",
    "                        title_font_color=\"black\")\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop segment 1\n",
    "def crop_segmemt_1(mot_dict): \n",
    "    \n",
    "    min_time = min([ mot_dict[k].shape[0] for k in mot_dict ])\n",
    "    \n",
    "    if 'SQT01_segment_1' in mot_dict:\n",
    "        mot_dict['SQT01_segment_1'] = mot_dict['SQT01_segment_1'].tail(min_time)\n",
    "    \n",
    "    return mot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2/21 [00:00<00:01, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 46)\n",
      "(31, 46)\n",
      "(133, 46)\n",
      "(191, 46)\n",
      "(132, 46)\n",
      "Simulation did not converge:  c613945f-1570-4011-93a4-8c8c6408e2cf SQT01_segment_3\n",
      "Simulation did not converge:  c613945f-1570-4011-93a4-8c8c6408e2cf SQT01_segment_1\n",
      "Simulation did not converge:  c613945f-1570-4011-93a4-8c8c6408e2cf SQT01_segment_2\n",
      "Simulation did not converge:  dfda5c67-a512-4ca2-a4b3-6a7e22599732 SQT01_segment_3\n",
      "Simulation did not converge:  dfda5c67-a512-4ca2-a4b3-6a7e22599732 SQT01_segment_1\n",
      "Simulation did not converge:  dfda5c67-a512-4ca2-a4b3-6a7e22599732 SQT01_segment_2\n",
      "(156, 46)\n",
      "(447, 46)\n",
      "(146, 46)\n",
      "(156, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 6/21 [00:00<00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 46)\n",
      "(159, 46)\n",
      "(163, 46)\n",
      "Simulation did not converge:  0e10a4e3-a93f-4b4d-9519-d9287d1d74eb SQT01_segment_1\n",
      "(157, 46)\n",
      "(141, 46)\n",
      "(162, 46)\n",
      "(139, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 9/21 [00:00<00:00, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 46)\n",
      "(603, 46)\n",
      "(157, 46)\n",
      "(127, 46)\n",
      "(232, 46)\n",
      "(143, 46)\n",
      "(108, 46)\n",
      "Simulation did not converge:  c28e768f-6e2b-4726-8919-c05b0af61e4a SQT01_segment_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 16/21 [00:00<00:00, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 46)\n",
      "Simulation did not converge:  fb6e8f87-a1cc-48b4-8217-4e8b160602bf SQT01_segment_3\n",
      "Simulation did not converge:  fb6e8f87-a1cc-48b4-8217-4e8b160602bf SQT01_segment_1\n",
      "Simulation did not converge:  fb6e8f87-a1cc-48b4-8217-4e8b160602bf SQT01_segment_2\n",
      "(130, 46)\n",
      "(225, 46)\n",
      "(122, 46)\n",
      "Simulation did not converge:  d66330dc-7884-4915-9dbb-0520932294c4 SQT01_segment_3\n",
      "(554, 46)\n",
      "(116, 46)\n",
      "Simulation did not converge:  0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45 SQT01_segment_3\n",
      "(422, 46)\n",
      "Simulation did not converge:  0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45 SQT01_segment_2\n",
      "(171, 46)\n",
      "(229, 46)\n",
      "Simulation did not converge:  2345d831-6038-412e-84a9-971bc04da597 SQT01_segment_2\n",
      "Simulation did not converge:  0a959024-3371-478a-96da-bf17b1da15a9 SQT01_segment_3\n",
      "Simulation did not converge:  0a959024-3371-478a-96da-bf17b1da15a9 SQT01_segment_1\n",
      "Simulation did not converge:  0a959024-3371-478a-96da-bf17b1da15a9 SQT01_segment_2\n",
      "Simulation did not converge:  ef656fe8-27e7-428a-84a9-deb868da053d SQT01_segment_3\n",
      "Simulation did not converge:  ef656fe8-27e7-428a-84a9-deb868da053d SQT01_segment_1\n",
      "Simulation did not converge:  ef656fe8-27e7-428a-84a9-deb868da053d SQT01_segment_2\n",
      "(122, 46)\n",
      "Simulation did not converge:  c08f1d89-c843-4878-8406-b6f9798a558e SQT01_segment_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 20.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 46)\n",
      "(197, 46)\n",
      "(241, 46)\n",
      "(150, 46)\n",
      "(112, 46)\n",
      "Simulation did not converge:  8dc21218-8338-4fd4-8164-f6f122dc33d9 SQT01_segment_1\n",
      "(115, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PPE Files containing with MCS Scores\n",
    "mcs_sessions = [\"349e4383-da38-4138-8371-9a5fed63a56a\",\"015b7571-9f0b-4db4-a854-68e57640640d\",\"c613945f-1570-4011-93a4-8c8c6408e2cf\",\"dfda5c67-a512-4ca2-a4b3-6a7e22599732\",\"7562e3c0-dea8-46f8-bc8b-ed9d0f002a77\",\"275561c0-5d50-4675-9df1-733390cd572f\",\"0e10a4e3-a93f-4b4d-9519-d9287d1d74eb\",\"a5e5d4cd-524c-4905-af85-99678e1239c8\",\"dd215900-9827-4ae6-a07d-543b8648b1da\",\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"c28e768f-6e2b-4726-8919-c05b0af61e4a\",\"fb6e8f87-a1cc-48b4-8217-4e8b160602bf\",\"e6b10bbf-4e00-4ac0-aade-68bc1447de3e\",\"d66330dc-7884-4915-9dbb-0520932294c4\",\"0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45\",\"2345d831-6038-412e-84a9-971bc04da597\",\"0a959024-3371-478a-96da-bf17b1da15a9\",\"ef656fe8-27e7-428a-84a9-deb868da053d\",\"c08f1d89-c843-4878-8406-b6f9798a558e\",\"d2020b0e-6d41-4759-87f0-5c158f6ab86a\",\"8dc21218-8338-4fd4-8164-f6f122dc33d9\"]\n",
    "\n",
    "mcs_scores = [4,4,2,3,2,4,3,3,2,3,0,3,4,2,2,3,4,4,3,3,3]\n",
    "mcs_scores = dict(zip(mcs_sessions,mcs_scores))\n",
    "\n",
    "PPE_Subjects = [\"PPE09182201\",\"PPE09182202\",\"PPE09182203\",\"PPE09182204\",\"PPE09182205\",\"PPE09182206\",\"PPE09182207\",\"PPE09182208\",\"PPE09182209\",\"PPE091822010\",\"PPE09182211\",\"PPE09182212\",\"PPE09182213\",\"PPE09182214\",\"PPE09182215\",\"PPE09182216\",\"PPE09182217\",\"PPE09182218\",\"PPE09182219\",\"PPE09182220\",\"PPE09182221\"]\n",
    "PPE_Subjects = dict(zip(mcs_sessions,PPE_Subjects))\n",
    "\n",
    "simulation_data = load_simulation_data(mcs_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "def convert2splines(simulation_data): \n",
    "\n",
    "    time_normalized_simulation_data = {}\n",
    "    for trial in simulation_data: \n",
    "        \n",
    "        T = simulation_data[trial].shape\n",
    "        spline_data = []\n",
    "        time_data = np.array(simulation_data[trial]['time'])\n",
    "        for header_ind, (header, series) in enumerate(simulation_data[trial].items()):\n",
    "            \n",
    "            spline = CubicSpline(time_data, np.array(series))\n",
    "\n",
    "            spline_input = np.linspace(time_data[0],time_data[-1],101)\n",
    "            spline_data.append(spline(spline_input))\n",
    "            \n",
    "        spline_data = np.array(spline_data)\n",
    "        out = pd.DataFrame(data=spline_data.T, columns=simulation_data[trial].columns)\n",
    "        \n",
    "        time_normalized_simulation_data[trial] = out\n",
    "    \n",
    "    return time_normalized_simulation_data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "skip_sessions = [mcs_sessions[0], ]\n",
    "save_locations = {}\n",
    "os.makedirs(\"pdfs\",exist_ok=True)\n",
    "\n",
    "time_normalized_simulation_data = {} \n",
    "\n",
    "for session_id in tqdm.tqdm(mcs_sessions):\n",
    "    # Check if all the details that have to be plotted exist\n",
    "    if session_id in simulation_data \\\n",
    "        and session_id in PPE_Subjects\\\n",
    "        and  session_id in mcs_scores\\\n",
    "        and 0 < mcs_scores[session_id] < 5: \n",
    "        \n",
    "        if session_id in skip_sessions: \n",
    "            continue \n",
    "        \n",
    "        simulation_data[session_id] = crop_segmemt_1(simulation_data[session_id])\n",
    "        \n",
    "        time_normalized_simulation_data[session_id] = convert2splines(simulation_data[session_id])\n",
    "        \n",
    "        \n",
    "        fig = plot_simulation_data(session_id, \\\n",
    "            time_normalized_simulation_data[session_id], \\\n",
    "            mcs_scores[session_id],\\\n",
    "            PPE_Subjects[session_id])\n",
    "\n",
    "        plotly.io.write_image(fig, f'pdfs/{session_id}_mcs_{mcs_scores[session_id]}.pdf', format='pdf')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lumbar_bending',\n",
       " 'lumbar_extension',\n",
       " 'lumbar_rotation',\n",
       " 'pelvis_list',\n",
       " 'pelvis_tilt',\n",
       " 'pelvis_rotation',\n",
       " 'hip_adduction_l',\n",
       " 'hip_flexion_l',\n",
       " 'hip_rotation_l',\n",
       " 'hip_adduction_r',\n",
       " 'hip_flexion_r',\n",
       " 'hip_rotation_r',\n",
       " 'knee_angle_l',\n",
       " 'knee_angle_r',\n",
       " 'ankle_angle_l',\n",
       " 'ankle_angle_r']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_mapping = {\n",
    "        'Trunk Obliquity': 'lumbar_bending',\n",
    "        'Trunk Tilt': 'lumbar_extension',\n",
    "        'Trunk Rotation': 'lumbar_rotation',\n",
    "        'Pelvic Obliquity': 'pelvis_list',\n",
    "        'Pelvic Tilt': 'pelvis_tilt',\n",
    "        'Pelvic Rotation': 'pelvis_rotation',\n",
    "        'Left Hip Ab/Adduction': 'hip_adduction_l',\n",
    "        'Left Hip Flexion/Extension': 'hip_flexion_l',\n",
    "        'Left Hip Rotation': 'hip_rotation_l',\n",
    "        'Right Hip Ab/Adduction': 'hip_adduction_r',\n",
    "        'Right Hip Flexion/Extension': 'hip_flexion_r',\n",
    "        'Right Hip Rotation': 'hip_rotation_r',\n",
    "        'Left Knee Flexion/Extension': 'knee_angle_l',\n",
    "        'Right Knee Flexion/Extension': 'knee_angle_r',\n",
    "        'Left Ankle Dorsi/Plantar': 'ankle_angle_l',\n",
    "        'Right Ankle Dorsi/Plantar': 'ankle_angle_r', \n",
    "    }\n",
    "list(plot_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3511351/3166064687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lumbar_bending'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lumbar_extension'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lumbar_rotation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pelvis_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pelvis_tilt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pelvis_rotation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hip_adduction_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hip_flexion_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hip_rotation_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hip_adduction_r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hip_flexion_r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hip_rotation_r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'knee_angle_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'knee_angle_r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ankle_angle_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ankle_angle_r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstd_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot mean and std using time-normalized data\n",
    "headers = ['lumbar_bending', 'lumbar_extension', 'lumbar_rotation', 'pelvis_list', 'pelvis_tilt', 'pelvis_rotation', 'hip_adduction_l', 'hip_flexion_l', 'hip_rotation_l', 'hip_adduction_r', 'hip_flexion_r', 'hip_rotation_r', 'knee_angle_l', 'knee_angle_r', 'ankle_angle_l', 'ankle_angle_r']\n",
    "\n",
    "mean_data = np.zeros((101,len(headers)))\n",
    "std_data = np.zeros((101,len(headers)))\n",
    "total_trials = 0\n",
    "for session_id in time_normalized_simulation_data: \n",
    "    for trail in time_normalized_simulation_data[session_id]: \n",
    "        data = time_normalized_simulation_data[session_id][trail][headers].to_numpy()\n",
    "        mean_data += data\n",
    "        std_data += data**2\n",
    "        total_trials += 1\n",
    "\n",
    "mean_data /= total_trials\n",
    "std_data = np.sqrt(std_data/total_trials - mean_data) \n",
    "\n",
    "mean_df = pd.DataFrame(data=mean_data, columns=headers)\n",
    "std_df = pd.DataFrame(data=mean_data, columns=headers)\n",
    "\n",
    "# Create 4x4 subplots (we'll only use 14 of them)\n",
    "fig = make_subplots(rows=6, cols=3, subplot_titles=(\n",
    "    'Trunk Obliquity', 'Trunk Tilt', 'Trunk Rotation',\n",
    "    'Pelvic Obliquity', 'Pelvic Tilt', 'Pelvic Rotation',\n",
    "    'Left Hip Ab/Adduction', 'Left Hip Flexion/Extension', 'Left Hip Rotation',\n",
    "    'Right Hip Ab/Adduction', 'Right Hip Flexion/Extension', 'Right Hip Rotation',\n",
    "    'Left Knee Flexion/Extension', 'Right Knee Flexion/Extension', '',\n",
    "    'Left Ankle Dorsi/Plantar', 'Right Ankle Dorsi/Plantar', ''\n",
    "))\n",
    "\n",
    "# Define the mapping of DataFrame columns to plot titles\n",
    "plot_mapping = {\n",
    "    'Trunk Obliquity': 'lumbar_bending',\n",
    "    'Trunk Tilt': 'lumbar_extension',\n",
    "    'Trunk Rotation': 'lumbar_rotation',\n",
    "    'Pelvic Obliquity': 'pelvis_list',\n",
    "    'Pelvic Tilt': 'pelvis_tilt',\n",
    "    'Pelvic Rotation': 'pelvis_rotation',\n",
    "    'Left Hip Ab/Adduction': 'hip_adduction_l',\n",
    "    'Left Hip Flexion/Extension': 'hip_flexion_l',\n",
    "    'Left Hip Rotation': 'hip_rotation_l',\n",
    "    'Right Hip Ab/Adduction': 'hip_adduction_r',\n",
    "    'Right Hip Flexion/Extension': 'hip_flexion_r',\n",
    "    'Right Hip Rotation': 'hip_rotation_r',\n",
    "    'Left Knee Flexion/Extension': 'knee_angle_l',\n",
    "    'Right Knee Flexion/Extension': 'knee_angle_r',\n",
    "    'Knee Flexion/Extension': '',\n",
    "    'Left Ankle Dorsi/Plantar': 'ankle_angle_l',\n",
    "    'Right Ankle Dorsi/Plantar': 'ankle_angle_r', \n",
    "    'Ankle Dorsi/Plantar': '',\n",
    "}\n",
    "\n",
    "# Colors for left and right sides\n",
    "colors = {'left': 'blue', 'right': 'red'}\n",
    "\n",
    "\n",
    "\n",
    "# Create each subplot\n",
    "for i, (title, columns) in enumerate(plot_mapping.items()):\n",
    "    row = i // 3 + 1\n",
    "    col = i % 3 + 1\n",
    "\n",
    "    if columns == '': \n",
    "        continue  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot single trace\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=np.linspace(0,1,num=101), y=np.array(mean_df[columns]), showlegend=False, name=f'{title}'), row=row, col=col)\n",
    "    x = np.linspace(0,1,num=101)\n",
    "    fig.add_trace(go.Scatter(x=list(x) + list(x)[::-1],   y=list(np.array(mean_df[columns]) + np.array(std_df[columns])) + list(np.array(mean_df[columns]) - np.array(std_df[columns]))[::-1] , mode='lines', line=dict(width=0), name=f'{title} Upper Bound', showlegend=False, fill='toself',hoverinfo=\"skip\",), row=row, col=col)\n",
    "\n",
    "    # Update y-axis label\n",
    "    fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "# Update x-axis label for the bottom row\n",
    "for col in range(1, 6):\n",
    "    for row in range(1,6):\n",
    "        fig.update_xaxes(title_text='% SQT Cycle (Seconds)', row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1500, width=1000,\n",
    "                    showlegend=False,  title_x=0.5,\n",
    "                    title_text=f\"All subjects Kinematics\",\n",
    "                    font_family=\"Times New Roman\",\n",
    "                    font_color=\"black\",\n",
    "                    title_font_family=\"Times New Roman\",\n",
    "                    title_font_color=\"black\")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "plotly.io.write_image(fig, f'pdfs/all_subject_kinematics.pdf', format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /home/ubuntu/.conda/envs/mdm/lib/python3.7/site-packages (4.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /home/ubuntu/.conda/envs/mdm/lib/python3.7/site-packages (from pypdf) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/mdm/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning:\n",
      "\n",
      "PdfMerger is deprecated and will be removed in pypdf 5.0.0. Use PdfWriter instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfMerger\n",
    "import glob\n",
    "\n",
    "pdfs = os.listdir(\"pdfs\")\n",
    "pdfs.remove(\"all_subject_kinematics.pdf\")\n",
    "pdfs.insert(0,\"all_subject_kinematics.pdf\")\n",
    "merger = PdfMerger()\n",
    "\n",
    "for pdf in pdfs:\n",
    "    merger.append(os.path.join(\"pdfs\",pdf))\n",
    "\n",
    "merger.write(\"MCS-Subjects-SQT-Kinematics.pdf\")\n",
    "merger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = os.listdir(\"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0e10a4e3-a93f-4b4d-9519-d9287d1d74eb_mcs_3.pdf',\n",
       " '3d1207bf-192b-486a-b509-d11ca90851d7_mcs_3.pdf',\n",
       " '00000all_subject_kinematics.pdf',\n",
       " 'd66330dc-7884-4915-9dbb-0520932294c4_mcs_2.pdf',\n",
       " 'dd215900-9827-4ae6-a07d-543b8648b1da_mcs_2.pdf',\n",
       " '8dc21218-8338-4fd4-8164-f6f122dc33d9_mcs_3.pdf',\n",
       " '275561c0-5d50-4675-9df1-733390cd572f_mcs_4.pdf',\n",
       " '0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45_mcs_2.pdf',\n",
       " '015b7571-9f0b-4db4-a854-68e57640640d_mcs_4.pdf',\n",
       " 'a5e5d4cd-524c-4905-af85-99678e1239c8_mcs_3.pdf',\n",
       " 'e6b10bbf-4e00-4ac0-aade-68bc1447de3e_mcs_4.pdf',\n",
       " '7562e3c0-dea8-46f8-bc8b-ed9d0f002a77_mcs_2.pdf',\n",
       " 'd2020b0e-6d41-4759-87f0-5c158f6ab86a_mcs_3.pdf',\n",
       " 'c08f1d89-c843-4878-8406-b6f9798a558e_mcs_3.pdf',\n",
       " '2345d831-6038-412e-84a9-971bc04da597_mcs_3.pdf']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T2M-GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

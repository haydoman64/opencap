{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: \n",
    "\n",
    "### Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders for .mot files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader for .mot files\n",
    "\n",
    "def read_header(mot_file,header_line=10): \n",
    "    if not os.path.isfile(mot_file): \n",
    "        return []\n",
    "\n",
    "    try:         \n",
    "        with open(mot_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            headers = lines[header_line]\n",
    "            headers = headers.split()\n",
    "            return headers\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to load headers for file:{mot_file}. Error:{e}\")\n",
    "        return [] \n",
    "\n",
    "def storage_to_numpy(storage_file, excess_header_entries=0):\n",
    "    \"\"\"Returns the data from a storage file in a numpy format. Skips all lines\n",
    "    up to and including the line that says 'endheader'.\n",
    "    Parameters\n",
    "    ----------\n",
    "    storage_file : str\n",
    "        Path to an OpenSim Storage (.sto) file.\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray (or numpy structure array or something?)\n",
    "        Contains all columns from the storage file, indexable by column name.\n",
    "    excess_header_entries : int, optional\n",
    "        If the header row has more names in it than there are data columns.\n",
    "        We'll ignore this many header row entries from the end of the header\n",
    "        row. This argument allows for a hacky fix to an issue that arises from\n",
    "        Static Optimization '.sto' outputs.\n",
    "    Examples\n",
    "    --------\n",
    "    Columns from the storage file can be obtained as follows:\n",
    "        >>> data = storage2numpy('<filename>')\n",
    "        >>> data['ground_force_vy']\n",
    "    \"\"\"\n",
    "    # What's the line number of the line containing 'endheader'?\n",
    "    f = open(storage_file, 'r')\n",
    "\n",
    "    header_line = False\n",
    "    for i, line in enumerate(f):\n",
    "        if header_line:\n",
    "            column_names = line.split()\n",
    "            break\n",
    "        if line.count('endheader') != 0:\n",
    "            line_number_of_line_containing_endheader = i + 1\n",
    "            header_line = True\n",
    "    f.close()\n",
    "    # With this information, go get the data.\n",
    "    if excess_header_entries == 0:\n",
    "        names = True\n",
    "        skip_header = line_number_of_line_containing_endheader\n",
    "    else:\n",
    "        names = column_names[:-excess_header_entries]\n",
    "        skip_header = line_number_of_line_containing_endheader + 1\n",
    "    data = np.genfromtxt(storage_file, names=names,\n",
    "            skip_header=skip_header)\n",
    "\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_data.append(list(d))\n",
    "    new_data = np.array(new_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def storage_to_dataframe(storage_file, headers):\n",
    "    # Extract data\n",
    "    data = storage_to_numpy(storage_file)\n",
    "    data = np.array(data)\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_data.append(list(d))\n",
    "    new_data = np.array(new_data)\n",
    "    header_mapping = {header:i for i,header in enumerate(headers)}\n",
    "\n",
    "    out = pd.DataFrame(data=data['time'], columns=['time'])\n",
    "    for count, header in enumerate(headers):\n",
    "        out.insert(count + 1, header, new_data[:,count+1])    \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load simulation data into a dictionary called subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path ='/home/ubuntu/data/opencap-processing/Data/'\n",
    "\n",
    "# Load simulation for data for given list of sessions\n",
    "def load_simulation_data(mcs_sessions):\n",
    "    subjects = {}\n",
    "\n",
    "    for subject_name in tqdm.tqdm(mcs_sessions):\n",
    "\n",
    "        if not os.path.isdir(os.path.join(data_path, subject_name)): continue\n",
    "\n",
    "        subjects[subject_name] = {}\n",
    "\n",
    "        simulation_results_path = os.path.join(data_path, subject_name, 'OpenSimData','Dynamics')\n",
    "\n",
    "        for trial_name in os.listdir(simulation_results_path): \n",
    "            \n",
    "            if trial_name == \"SQT01\": # Contains same results as segment-1 \n",
    "                continue\n",
    "            \n",
    "            subjects[subject_name][trial_name] = {}\n",
    "            \n",
    "            kinetics_path = os.path.join(simulation_results_path, trial_name,f\"kinetics_{trial_name}_torque_driven.mot\")\n",
    "            mot_headers = read_header(kinetics_path,header_line=6)            \n",
    "                        \n",
    "            if len(mot_headers) == 0:\n",
    "                print(f\"Unable to load headers for file:\", subject_name,trial_name, kinetics_path)\n",
    "                continue \n",
    "            \n",
    "            # Remove time from headers\n",
    "            mot_headers.remove('time')\n",
    "\n",
    "            kinetics = storage_to_dataframe(kinetics_path, mot_headers)\n",
    "            \n",
    "            subjects[subject_name][trial_name]['kinetics'] = kinetics\n",
    "\n",
    "            kinematics_path = os.path.join(simulation_results_path, trial_name,f\"kinematics_activations_{trial_name}_torque_driven.mot\")\n",
    "            mot_headers = read_header(kinematics_path,header_line=10)\n",
    "\n",
    "            # Remove time from headers\n",
    "            mot_headers.remove('time')\n",
    "\n",
    "            if len(mot_headers) == 0:\n",
    "                print(f\"Unable to load headers for file:\", subject_name,kinematics_path)\n",
    "                continue \n",
    "\n",
    "            kinematics = storage_to_dataframe(kinematics_path, mot_headers)\n",
    "\n",
    "\n",
    "            subjects[subject_name][trial_name]['kinematics'] = kinematics\n",
    "\n",
    "            subjects[subject_name]['dof_names'] = kinematics.columns.tolist()    \n",
    "            \n",
    "    return subjects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per subject meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPE Files containing with MCS Scores\n",
    "mcs_sessions = [\"349e4383-da38-4138-8371-9a5fed63a56a\",\"015b7571-9f0b-4db4-a854-68e57640640d\",\"c613945f-1570-4011-93a4-8c8c6408e2cf\",\"dfda5c67-a512-4ca2-a4b3-6a7e22599732\",\"7562e3c0-dea8-46f8-bc8b-ed9d0f002a77\",\"275561c0-5d50-4675-9df1-733390cd572f\",\"0e10a4e3-a93f-4b4d-9519-d9287d1d74eb\",\"a5e5d4cd-524c-4905-af85-99678e1239c8\",\"dd215900-9827-4ae6-a07d-543b8648b1da\",\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"c28e768f-6e2b-4726-8919-c05b0af61e4a\",\"fb6e8f87-a1cc-48b4-8217-4e8b160602bf\",\"e6b10bbf-4e00-4ac0-aade-68bc1447de3e\",\"d66330dc-7884-4915-9dbb-0520932294c4\",\"0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45\",\"2345d831-6038-412e-84a9-971bc04da597\",\"0a959024-3371-478a-96da-bf17b1da15a9\",\"ef656fe8-27e7-428a-84a9-deb868da053d\",\"c08f1d89-c843-4878-8406-b6f9798a558e\",\"d2020b0e-6d41-4759-87f0-5c158f6ab86a\",\"8dc21218-8338-4fd4-8164-f6f122dc33d9\"]\n",
    "\n",
    "mcs_scores = [4,4,2,3,2,4,3,3,2,3,0,3,4,2,2,3,4,4,3,3,3]\n",
    "mcs_scores = dict(zip(mcs_sessions,mcs_scores))\n",
    "\n",
    "PPE_Subjects = [\"PPE09182201\",\"PPE09182202\",\"PPE09182203\",\"PPE09182204\",\"PPE09182205\",\"PPE09182206\",\"PPE09182207\",\"PPE09182208\",\"PPE09182209\",\"PPE091822010\",\"PPE09182211\",\"PPE09182212\",\"PPE09182213\",\"PPE09182214\",\"PPE09182215\",\"PPE09182216\",\"PPE09182217\",\"PPE09182218\",\"PPE09182219\",\"PPE09182220\",\"PPE09182221\"]\n",
    "PPE_Subjects = dict(zip(mcs_sessions,PPE_Subjects))\n",
    "\n",
    "subjects = load_simulation_data(mcs_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "def time_normalization(time_series,duration=101): \n",
    "\n",
    "    orig_time_space = np.linspace(0,1,len(time_series))\n",
    "        \n",
    "    spline = CubicSpline(orig_time_space, time_series)\n",
    "\n",
    "    spline_input = np.linspace(0,1,duration)\n",
    "    split_output = spline(spline_input)\n",
    "            \n",
    "    return split_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot temporal segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_names_mapping = {\n",
    "    'lumbar_bending': 'Trunk Obliquity',\n",
    "    'lumbar_extension': 'Trunk Tilt',\n",
    "    'lumbar_rotation': 'Trunk Rotation',\n",
    "    'pelvis_list': 'Pelvic Obliquity',\n",
    "    'pelvis_tilt': 'Pelvic Tilt',\n",
    "    'pelvis_rotation': 'Pelvic Rotation',\n",
    "    'hip_adduction_l': 'Left Hip Ab/Adduction',\n",
    "    'hip_flexion_l': 'Left Hip Flexion/Extension',\n",
    "    'hip_rotation_l': 'Left Hip Rotation',\n",
    "    'hip_adduction_r': 'Right Hip Ab/Adduction',\n",
    "    'hip_flexion_r': 'Right Hip Flexion/Extension',\n",
    "    'hip_rotation_r': 'Right Hip Rotation',\n",
    "    'knee_angle_l': 'Left Knee Flexion/Extension',\n",
    "    'knee_angle_r': 'Right Knee Flexion/Extension',\n",
    "    'ankle_angle_l': 'Left Ankle Dorsi/Plantar',\n",
    "    'ankle_angle_r': 'Right Ankle Dorsi/Plantar'\n",
    "}\n",
    "\n",
    "def get_plotting_data(subject,trial,remove_headers=['pelvis_tx','pelvis_ty','pelvis_tz']): \n",
    "    # Get the subject data and remove pelvis translation \n",
    "\n",
    "    headers = subject['dof_names'] \n",
    "\n",
    "    keep_index = [headers.index(header)  for header in plot_names_mapping.keys()]\n",
    "\n",
    "    plot_headers = [headers[i] for i in keep_index]\n",
    "\n",
    "    plot_data = {}\n",
    "    plot_data['kinematics'] = subject[trial]['kinematics'] \n",
    "    plot_data['kinematics'] = plot_data['kinematics'][plot_headers]\n",
    "\n",
    "\n",
    "    plot_headers_kinetics = [ h +'_moment'  for h in plot_headers]\n",
    "    plot_data['kinetics'] = subject[trial]['kinetics'] \n",
    "    plot_data['kinetics'] = plot_data['kinetics'][plot_headers_kinetics]\n",
    "\n",
    "\n",
    "    for k in plot_data:\n",
    "        assert plot_data[k].shape[-1] == len(plot_headers), f\"Length of headers should match headers length. Found:{plot_data[k].shape[-1]} , expected:{len(plot_headers)}\"\n",
    "\n",
    "        plot_data[k] = plot_data[k].to_numpy()\n",
    "\n",
    "    return plot_headers, plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Temporal Segmentation\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def find_valleys_in_max_angular_velocity(max_angular_velocity,seconds_per_frame=0.01,allowed_height_difference_threshold=0.1):\n",
    "    \"\"\"\n",
    "        Find peaks in the angular velocity of a time series of rotation vectors.\n",
    "\n",
    "        Args:\n",
    "        angular_velocity: A numpy array of shape (N, 24) containing angular velocities in radians per second.\n",
    "        framerate: The frame rate of the data in Hz.\n",
    "\n",
    "        Returns: A numpy array of shape (M,) containing the indices of the peaks in the angular velocity.\n",
    "    \"\"\"\n",
    "\n",
    "    diff = np.max(max_angular_velocity) - np.min(max_angular_velocity)\n",
    "    min_height = np.min(max_angular_velocity) + allowed_height_difference_threshold*diff\n",
    "\n",
    "    distance_between_valleys = max(1,int(1/(10*seconds_per_frame)))\n",
    "    # distance_between_valleys = 1\n",
    "\n",
    "    print(f\"distance between valleys={distance_between_valleys}\")\n",
    "    print(f\"Max allowed valley height={min_height} allowed_height_difference_threshold={allowed_height_difference_threshold}\")\n",
    "    valleys, meta_data = find_peaks(-max_angular_velocity,distance=distance_between_valleys,height=-min_height)\n",
    "\n",
    "    print(\"Valleys\",valleys, \"Meta data: \",meta_data)\n",
    "\n",
    "    return valleys\n",
    "\n",
    "\n",
    "def find_best_n_segments(temporal_segmentation_data, num_segments, duplicate_threshold=0.75, rms_threshold=0.75):\n",
    "    \"\"\"\n",
    "        Validate segments using DTW\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for trial in temporal_segmentation_data:\n",
    "\n",
    "        max_pose_velocity = temporal_segmentation_data[trial]['max_pose_velocity']\n",
    "        valleys = temporal_segmentation_data[trial]['change_points']\n",
    "        \n",
    "\n",
    "        if len(valleys) < num_segments -1 : continue\n",
    "\n",
    "        if len(valleys) > 25: \n",
    "            valleys = np.sort(np.random.choice(valleys,25,replace=False))\n",
    "\n",
    "        # Add first and last frame for completeness\n",
    "        valleys = [0] + list(valleys) + [len(max_pose_velocity)-1]\n",
    "        valleys = np.array(valleys)\n",
    "\n",
    "        # In some cases there could a single valley which defines the start and the stop cycle. \n",
    "        # If that is the case, we need to duplicate the valley\n",
    "        # Check if a particular valley is too far to the adjacent valleys. If so, duplicate it.\n",
    "        # If the distance between the two adjacent valleys is greater than 1/2*average segment duaration, duplicate the valley \n",
    "        valley_copys = []\n",
    "        valley_threshold = (len(max_pose_velocity)/num_segments)*duplicate_threshold\n",
    "        for i,v in enumerate(valleys):\n",
    "            if i == 0: continue\n",
    "            if i == len(valleys)-1: continue \n",
    "\n",
    "\n",
    "            if (valleys[i+1] - valleys[i])  > valley_threshold and (valleys[i] - valleys[i-1])  > valley_threshold: \n",
    "                valley_copys.append(valleys[i])\n",
    "        \n",
    "        valleys = np.concatenate([valleys,valley_copys]).astype(int)\n",
    "        valleys.sort()\n",
    "\n",
    "\n",
    "        # Start-Stop candidates\n",
    "        print(f\"Start-Stop Candidates for {trial_name}\",valleys)\n",
    "        temporal_segmentation_data[trial]['change_points'] = valleys\n",
    "\n",
    "    # from tslearn.barycenters import dtw_barycenter_averaging\n",
    "    from itertools import combinations\n",
    "\n",
    "    best_combination = {} \n",
    "    best_combination_score = np.inf\n",
    "    best_combination_data = ()\n",
    "\n",
    "\n",
    "    ## Hard tests for filtet out invalid combinations \n",
    "    rms_sequence = np.sqrt(np.sum(max_pose_velocity**2)) # RMS for entire sequence. If some segment has motion less than the 1/2*num_segments, probably no motion is happening in it.  \n",
    "    \n",
    "    for trial in temporal_segmentation_data:\n",
    "        valleys = temporal_segmentation_data[trial]['change_points']\n",
    "        max_pose_velocity = temporal_segmentation_data[trial]['max_pose_velocity']\n",
    "        \n",
    "        for cur_comb in combinations(valleys, 2*num_segments):\n",
    "        \n",
    "            segments = [    [cur_comb[i*2 + 0],cur_comb[i*2 + 1]] for i in range(num_segments)    ]\n",
    "\n",
    "            rms_segments = [np.sqrt(np.sum(max_pose_velocity[segment[0]:segment[1]]**2)) for segment in segments]\n",
    "\n",
    "            if np.min(rms_segments) < rms_sequence*rms_threshold/num_segments:\n",
    "                continue\n",
    "\n",
    "            print(\"Testing segments\",segments,\"RMS Sequence:\", rms_sequence,\"RMS Threshold:\",rms_sequence*rms_threshold/num_segments)\n",
    "            print(rms_segments)\n",
    "\n",
    "            if 'valid_segments' not in temporal_segmentation_data[trial]: \n",
    "                temporal_segmentation_data[trial]['valid_segments'] = []\n",
    "            \n",
    "            temporal_segmentation_data[trial]['valid_segments'].append(segments)\n",
    "    \n",
    "    \n",
    "    def compute_combination_score(combination): \n",
    "        \n",
    "        print(f\"Computing combination score:{combination}\")\n",
    "        time_series = []\n",
    "        for trial in combination: \n",
    "            segments = combination[trial]   \n",
    "            max_pose_velocity = temporal_segmentation_data[trial]['max_pose_velocity']\n",
    "            # Normalize Time Series\n",
    "            time_normalized_series = np.array([time_normalization(max_pose_velocity[segment[0]:segment[1]]) for segment in segments])\n",
    "            time_series.append(time_normalized_series)\n",
    "        # Minimize STD at for entire duration\n",
    "        combination_score = np.sum(np.std(time_series,axis=0))\n",
    "        \n",
    "        return combination_score        \n",
    "    \n",
    "    # Sort the trial names in data\n",
    "    trials_names = sorted([k for k in temporal_segmentation_data], key=lambda x : int(x.split('_')[-1]))\n",
    "    \n",
    "    # Run recursion on all trials and return the combinations with the best matching score acrross trials. on all valid combinations. If num_combiations \n",
    "    def dfs(ind, combination):\n",
    "        if ind == len(temporal_segmentation_data): \n",
    "            combination_score = compute_combination_score(combination)\n",
    "            return combination, combination_score\n",
    "            \n",
    "        trial_name = trials_names[ind] \n",
    "        if 'valid_segments' not in temporal_segmentation_data[trial_name] or len(temporal_segmentation_data[trial_name]['valid_segments']) == 0:\n",
    "            return dfs(ind+1, combination)\n",
    "        \n",
    "        print(f\"{ind} combinations:{combinations}\")\n",
    "        \n",
    "        best_combination_score = np.inf\n",
    "        best_combination = None\n",
    "        for trial_combination in temporal_segmentation_data[trial_name]['valid_segments']: \n",
    "            combination[trial_name] = trial_combination\n",
    "            combination, combination_score = dfs(ind+1, combination)\n",
    "            \n",
    "            \n",
    "            if combination_score < best_combination_score: \n",
    "                best_combination_score = combination_score\n",
    "                best_combination = combination.copy()\n",
    "        \n",
    "            del combination[trial_name] # Remove combination, try another combination\n",
    "        \n",
    "        print(f\"Best Score for: {ind} {best_combination_score} best_combination:{best_combination} \")\n",
    "        \n",
    "        return best_combination, best_combination_score\n",
    "                     \n",
    "    best_combination, best_combination_score = dfs(0, {}) \n",
    "    \n",
    "    if np.isinf(best_combination_score):\n",
    "        print(\"Could not find a valid segments. All combinations below RMS threshold\") \n",
    "        return {}, np.inf\n",
    "        \n",
    "    return best_combination,best_combination_score\n",
    "\n",
    "\n",
    "def temporal_segementation(data,headers, seconds_per_frame=0.01,visualize=True,num_segments=5,allowed_height_difference_threshold=0.1,fig_title=None,isdeg=True):\n",
    "    \"\"\"\n",
    "        Find segments in the angular velocity of a time series of rotation vectors.\n",
    "        params:\n",
    "            data: A dictionary containing the pose_params\n",
    "\n",
    "        returns: \n",
    "            segments: A list of tuples containing the start and end indices of the segments.\n",
    "    \"\"\"\n",
    "    trials_names = sorted([k for k in data], key=lambda x : int(x.split('_')[-1])) \n",
    " \n",
    "    # Create subplots\n",
    "    fig = plotly.subplots.make_subplots(rows=2, cols=len(data), subplot_titles=[ f\"{trial_index}. Start-Stop:{trial_name} \" for trial_index, trial_name in enumerate(trials_names)])\n",
    "    \n",
    "    temporal_segmentation_data = {} \n",
    "    \n",
    "    # Sort the trial names in data\n",
    "\n",
    "\n",
    "    for trial_index, trial_name in enumerate(trials_names):\n",
    "        \n",
    "        print(f\"Finding valleys in For {trial_index}:{trial_name}\")\n",
    "        \n",
    "        pose_velocity = plot_data[trial_name]['kinematics']\n",
    "        \n",
    "        print(f\"  Time series: {pose_velocity.shape}\")\n",
    "\n",
    "        \n",
    "        # Smoothing Filter ## Note window length and polyorder should be adjusted based on the data\n",
    "        for i in range(len(headers)): \n",
    "            pose_velocity[:,i] = savgol_filter(pose_velocity[:,i], window_length=21, polyorder=3)\n",
    "\n",
    "        # Only consider knee joints kinematics\n",
    "        knee_indices = [i for i,header in enumerate(headers) if \"knee\" in header.lower()]\n",
    "        max_pose_velocity = np.max(pose_velocity[:,knee_indices],axis=1)\n",
    "\n",
    "        x = np.arange(len(max_pose_velocity))*seconds_per_frame\n",
    "\n",
    "        if not isdeg:\n",
    "            max_pose_velocity = np.rad2deg(max_pose_velocity)\n",
    "\n",
    "        for i in range(len(headers)): \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x,\n",
    "                y=pose_velocity[:,i],\n",
    "                mode='lines',\n",
    "                name=plot_headers[i],\n",
    "                showlegend=True),row=1,col=trial_index+1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=max_pose_velocity,\n",
    "            mode='lines',\n",
    "            name='Knee Kinematics',\n",
    "            showlegend=False\n",
    "        ),row=2,col=trial_index+1)\n",
    "        \n",
    "        change_points = find_valleys_in_max_angular_velocity(max_pose_velocity,seconds_per_frame=seconds_per_frame,allowed_height_difference_threshold=allowed_height_difference_threshold)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x[change_points],\n",
    "            y=max_pose_velocity[change_points],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color='red',\n",
    "                size=16,\n",
    "                symbol='arrow-up'\n",
    "            ),\n",
    "            name='change_points'\n",
    "        ),row=2,col=trial_index+1)\n",
    "            \n",
    "        temporal_segmentation_data[trial_name] = {'change_points':change_points, 'max_pose_velocity': max_pose_velocity}\n",
    "    \n",
    "    # fig.show()\n",
    "        \n",
    "    segments_all_trial,segment_score = find_best_n_segments(temporal_segmentation_data,num_segments=num_segments)\n",
    "    \n",
    "            \n",
    "    for trial_index, trial_name in enumerate(trials_names):\n",
    "\n",
    "        change_points = temporal_segmentation_data[trial_name]['change_points']\n",
    "        max_pose_velocity = temporal_segmentation_data[trial_name]['max_pose_velocity']\n",
    "        segments = np.array(segments_all_trial[trial_name])\n",
    "\n",
    "        print(segments,trial_name)\n",
    "\n",
    "        x = np.arange(len(max_pose_velocity))*seconds_per_frame\n",
    "\n",
    "        if not isdeg:\n",
    "            max_pose_velocity = np.rad2deg(max_pose_velocity)\n",
    "        \n",
    "        # Plot the line segments \n",
    "        if not np.isinf(segment_score): \n",
    "            empty_array = np.array([None]*segments.shape[0]).reshape((-1,1))\n",
    "            plot_y_segments = np.tile( np.max(max_pose_velocity).reshape((1,1)), segments.shape )\n",
    "            plot_y_segments = np.concatenate([plot_y_segments,empty_array],axis=1).reshape(-1)\n",
    "\n",
    "            plot_x_segments = np.concatenate([segments*seconds_per_frame,empty_array],axis=1).reshape(-1)\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=plot_x_segments,\n",
    "                y=plot_y_segments,\n",
    "                line_shape='linear',\n",
    "                name='Selected Segments'\n",
    "            ),row=2,col=trial_index+1)\n",
    "\n",
    "        else: \n",
    "            segments = None\n",
    "\n",
    "\n",
    "    # Update subplot titles\n",
    "    fig.update_layout(\n",
    "        title_text=fig_title if fig_title != '' or fig_title is not None else f'Temporal Segmentation using Knee Kinematics',\n",
    "        font=dict(family=\"Times New Roman\"),\n",
    "    )\n",
    " \n",
    "    # Set figure size\n",
    "    fig.update_layout(width=1000, height=400)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time (s)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Max Knee Flexion (deg)\", row=1, col=1)\n",
    "\n",
    "\n",
    "    if visualize: \n",
    "        # Show the figure\n",
    "        fig.show()\n",
    "\n",
    "    # fig.write_image(image_path + \"_angular.png\")\n",
    "    return fig, segments_all_trial\n",
    "\n",
    "\n",
    "\n",
    "###############################################################\n",
    "\n",
    "skip_subjects = [\"c08f1d89-c843-4878-8406-b6f9798a558e\",\"0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45\",\"c28e768f-6e2b-4726-8919-c05b0af61e4a\",\"0e10a4e3-a93f-4b4d-9519-d9287d1d74eb\",\"349e4383-da38-4138-8371-9a5fed63a56a\"]\n",
    "# skip_subjects = [mcs_sessions[0], mcs_sessions[1]]\n",
    "\n",
    "for subject_ind, subject_name in tqdm.tqdm(enumerate(mcs_sessions)):\n",
    "    \n",
    "    print(f\"Evaluating Id: {subject_ind} Name: {subject_name}\")\n",
    "    \n",
    "    if subject_name in skip_subjects: continue\n",
    "    \n",
    "    if len(subjects[subject_name]) <= 1:  # If dict is empty skip.\n",
    "        print(f\"Subject is empty:{subjects[subject_name]}\")    \n",
    "        continue\n",
    "    \n",
    "    print(f\" Data:{subjects[subject_name].keys()}\")\n",
    "    \n",
    "    \n",
    "    plot_headers = None\n",
    "    plot_data = {}\n",
    "\n",
    "    # Get seconds per frame \n",
    "    seconds_per_frame = 0 \n",
    "\n",
    "    for trial_name in subjects[subject_name]: \n",
    "        if trial_name == 'dof_names': continue  \n",
    "    \n",
    "    \n",
    "        if len(subjects[subject_name][trial_name]) <= 1:  # If dict is empty skip.\n",
    "            print(f\"Trial is empty:{subjects[subject_name][trial_name]}\") \n",
    "            continue \n",
    "        print(subjects[subject_name][trial_name].keys())\n",
    "    \n",
    "        trial_length = subjects[subject_name][trial_name]['kinematics']['time'].iloc[-1] - subjects[subject_name][trial_name]['kinematics']['time'].iloc[0]\n",
    "        if trial_length < 1: continue # Can't perform squat in less tha a second . \n",
    "        \n",
    "        \n",
    "        seconds_per_frame += trial_length\n",
    "        \n",
    "        plot_headers, plot_data[trial_name] = get_plotting_data(subjects[subject_name],trial_name)\n",
    "        \n",
    "        print(seconds_per_frame,subjects[subject_name][trial_name]['kinematics']['time'].iloc[-1],subjects[subject_name][trial_name]['kinematics']['time'].iloc[0])\n",
    "\n",
    "        print(f\"Subject:{subject_name} Trial Index:{trial_name} Length: {trial_length} Headers:{plot_headers}\")\n",
    "\n",
    "    if seconds_per_frame == 0: \n",
    "        print(\"Tracks are empty, skipping subject\")\n",
    "        continue\n",
    "\n",
    "    assert seconds_per_frame > 0, f\"Subject Index:{subject_ind} seconds_per_frame should be greater 0. Likely no trial found to evaluate.\" \n",
    "    \n",
    "    seconds_per_frame /= sum([len(plot_data[trial_name]['kinematics']) for trial_name in plot_data])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    fig_title = f\"Temporal Segmentation using Knee Kinematics for Subject:{subject_name}\"\n",
    "\n",
    "    num_segments = 1 # Number of segments per trial\n",
    "\n",
    "    # Temporal Segmentation (using knee angles kinematics since it gave the most reasonable results) \n",
    "    segments_fig, segments_all_trials = temporal_segementation(plot_data,plot_headers,\\\n",
    "                                      num_segments=num_segments, seconds_per_frame=seconds_per_frame,\\\n",
    "                                      allowed_height_difference_threshold=0.15,\\\n",
    "                                      isdeg=True,visualize=False,fig_title=fig_title)\n",
    "\n",
    "\n",
    "\n",
    "    os.makedirs(\"pdfs\",exist_ok=True)\n",
    "    plotly.io.write_image(segments_fig, f'pdfs/{PPE_Subjects[subject_name]}_segmentation.pdf', format='pdf')\n",
    "\n",
    "    if len(segments_all_trials) == 0: \n",
    "        print(\"Could not find segments\")\n",
    "        continue  \n",
    "    \n",
    "    # Update data information\n",
    "    for trial_name in segments_all_trials:\n",
    "        subjects[subject_name][trial_name]['segments'] = segments_all_trials[trial_name]\n",
    "    \n",
    "    subjects[subject_name]['seconds_per_frame'] = seconds_per_frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trials across distributions for trials \n",
    "def plot_simulation_data(headers,plot_data,title_text=\"Plot Data\",visualize=True,data_type='kinematics'): \n",
    "    \n",
    "    # assert plot_data.shape[-1] == 101, \"Length of data should be 101\"\n",
    "    num_rows = int(math.ceil(len(headers)/3))\n",
    "    num_cols = 3\n",
    "    # Create 4x4 subplots (we'll only use 14 of them)\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[plot_names_mapping[header] for header in headers])\n",
    "\n",
    "    # Colors for left and right sides\n",
    "    colors = {'left': 'blue', 'right': 'red'}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i, header in enumerate(headers):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "        \n",
    "        title = plot_names_mapping[header]\n",
    "\n",
    "\n",
    "        # Plot every kinematics data\n",
    "        x = np.linspace(0,1,num=plot_data[i].shape[-1])\n",
    "        for j in range(plot_data[i].shape[0]):\n",
    "            fig.add_trace(go.Scatter(x=x, y=plot_data[i,j], name=f'{title}',showlegend=False), row=row, col=col)\n",
    "    \n",
    "        # Update y-axis label\n",
    "        if data_type == 'kinematics':\n",
    "            fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text='Nm', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "    # Update x-axis label for the bottom row\n",
    "    for col in range(1, num_rows+1):\n",
    "        for row in range(1,num_cols+1):\n",
    "            fig.update_xaxes(title_text='% SQT Cycle (Seconds)', row=row, col=col)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=2000, width=1000,\n",
    "                        showlegend=False,  title_x=0.5,\n",
    "                        title_text=title_text,\n",
    "                        font_family=\"Times New Roman\",\n",
    "                        font_color=\"black\",\n",
    "                        title_font_family=\"Times New Roman\",\n",
    "                        title_font_color=\"black\")\n",
    "\n",
    "    # Show the figure\n",
    "    if visualize: \n",
    "        fig.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ [ (k,t,subjects[k][t].keys()) for t in subjects[k] if t != 'dof_names' and t != 'seconds_per_frame'  ] for k in subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot indivifual sample & Store aggregate (mean, std, list ) values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "skip_subjects = [\"c08f1d89-c843-4878-8406-b6f9798a558e\",\"0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45\",\"c28e768f-6e2b-4726-8919-c05b0af61e4a\",\"0e10a4e3-a93f-4b4d-9519-d9287d1d74eb\",\"349e4383-da38-4138-8371-9a5fed63a56a\"]\n",
    "num_segments = 1\n",
    "\n",
    "mcs_sessions = [\"349e4383-da38-4138-8371-9a5fed63a56a\",\"015b7571-9f0b-4db4-a854-68e57640640d\",\"c613945f-1570-4011-93a4-8c8c6408e2cf\",\"dfda5c67-a512-4ca2-a4b3-6a7e22599732\",\"7562e3c0-dea8-46f8-bc8b-ed9d0f002a77\",\"275561c0-5d50-4675-9df1-733390cd572f\",\"0e10a4e3-a93f-4b4d-9519-d9287d1d74eb\",\"a5e5d4cd-524c-4905-af85-99678e1239c8\",\"dd215900-9827-4ae6-a07d-543b8648b1da\",\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"c28e768f-6e2b-4726-8919-c05b0af61e4a\",\"fb6e8f87-a1cc-48b4-8217-4e8b160602bf\",\"e6b10bbf-4e00-4ac0-aade-68bc1447de3e\",\"d66330dc-7884-4915-9dbb-0520932294c4\",\"0d9e84e9-57a4-4534-aee2-0d0e8d1e7c45\",\"2345d831-6038-412e-84a9-971bc04da597\",\"0a959024-3371-478a-96da-bf17b1da15a9\",\"ef656fe8-27e7-428a-84a9-deb868da053d\",\"c08f1d89-c843-4878-8406-b6f9798a558e\",\"d2020b0e-6d41-4759-87f0-5c158f6ab86a\",\"8dc21218-8338-4fd4-8164-f6f122dc33d9\"]\n",
    "\n",
    "mcs_scores = [4,4,2,3,2,4,3,3,2,3,0,3,4,2,2,3,4,4,3,3,3]\n",
    "mcs_scores = dict(zip(mcs_sessions,mcs_scores))\n",
    "\n",
    "PPE_Subjects = [\"PPE09182201\",\"PPE09182202\",\"PPE09182203\",\"PPE09182204\",\"PPE09182205\",\"PPE09182206\",\"PPE09182207\",\"PPE09182208\",\"PPE09182209\",\"PPE091822010\",\"PPE09182211\",\"PPE09182212\",\"PPE09182213\",\"PPE09182214\",\"PPE09182215\",\"PPE09182216\",\"PPE09182217\",\"PPE09182218\",\"PPE09182219\",\"PPE09182220\",\"PPE09182221\"]\n",
    "PPE_Subjects = dict(zip(mcs_sessions,PPE_Subjects))\n",
    "\n",
    "############### STORE Manual segmentation results here: \n",
    "manually_segment_subjects_list = [(\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"SQT01_segment_1\"),\n",
    "                                  (\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"SQT01_segment_2\"),\n",
    "                                  (\"3d1207bf-192b-486a-b509-d11ca90851d7\",\"SQT01_segment_3\"), \n",
    "                                  \n",
    "                                  (\"2345d831-6038-412e-84a9-971bc04da597\",\"SQT01_segment_1\")]\n",
    "\n",
    "manual_segments = {} \n",
    "for subject_name,trial_name in manually_segment_subjects_list: \n",
    "    if subject_name not in manual_segments: \n",
    "        manual_segments[subject_name] = {}\n",
    "\n",
    "    manual_segments[subject_name][trial_name] = copy.deepcopy(subjects[subject_name][trial_name]['segments'])\n",
    "\n",
    "    \n",
    "\n",
    "manual_segments[\"3d1207bf-192b-486a-b509-d11ca90851d7\"][\"SQT01_segment_3\"][0][0] += 15\n",
    "manual_segments[\"3d1207bf-192b-486a-b509-d11ca90851d7\"][\"SQT01_segment_3\"][0][1] += 15\n",
    "\n",
    "manual_segments[\"3d1207bf-192b-486a-b509-d11ca90851d7\"][\"SQT01_segment_1\"][0][0] += 40\n",
    "manual_segments[\"3d1207bf-192b-486a-b509-d11ca90851d7\"][\"SQT01_segment_1\"][0][1] += 40\n",
    "\n",
    "\n",
    "manual_segments[\"2345d831-6038-412e-84a9-971bc04da597\"][\"SQT01_segment_1\"][0][0] += 40 \n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n",
    "os.makedirs(\"pdfs\",exist_ok=True)\n",
    "\n",
    "aggregate_data = {}\n",
    "mcs_aggregate_data = {2:{}, 3:{}, 4:{}}\n",
    "for plotting_variable in ['kinematics','kinetics']:\n",
    "    aggregate_data[plotting_variable] = {}\n",
    "    aggregate_data[plotting_variable]['mean'] = np.zeros((len(plot_names_mapping),101))\n",
    "    aggregate_data[plotting_variable]['std'] = np.zeros((len(plot_names_mapping),101))\n",
    "\n",
    "\n",
    "total_trials = 0\n",
    "\n",
    "for subject_ind, subject_name in tqdm.tqdm(enumerate(subjects)):\n",
    "\n",
    "    # Check if all the details that have to be plotted exist    \n",
    "    if subject_name in skip_subjects: \n",
    "        continue \n",
    "    \n",
    "    \n",
    "    if subject_name in skip_subjects: continue\n",
    "    \n",
    "    if len(subjects[subject_name]) <= 1:  # If dict is empty skip.\n",
    "        print(f\"Subject is empty:{subjects[subject_name]}\")    \n",
    "        continue\n",
    "    \n",
    "    print(f\" Data:{subjects[subject_name].keys()}\")\n",
    "    \n",
    "    plot_headers = None\n",
    "    plot_data = {}\n",
    "\n",
    "    for trial_name in subjects[subject_name]: \n",
    "        if trial_name == 'dof_names': continue\n",
    "        if trial_name == 'seconds_per_frame': continue  \n",
    "        \n",
    "        if len(subjects[subject_name][trial_name]) <= 1:  # If dict is empty skip.\n",
    "            print(f\"Trial is empty:{subjects[subject_name][trial_name]}\") \n",
    "            continue \n",
    "        print(subjects[subject_name][trial_name].keys())\n",
    "    \n",
    "        trial_length = subjects[subject_name][trial_name]['kinematics']['time'].iloc[-1] - subjects[subject_name][trial_name]['kinematics']['time'].iloc[0]\n",
    "        if trial_length < 1: continue # Can't perform squat in less tha a second . \n",
    "        \n",
    " \n",
    "        plot_headers, plot_data_trial = get_plotting_data(subjects[subject_name],trial_name)\n",
    "        \n",
    "    \n",
    "        # Temporal Segmentation (using knee angles kinematics since it gave the most reasonable results) \n",
    "        if subject_name in manual_segments and trial_name in manual_segments[subject_name]:\n",
    "            segments = manual_segments[subject_name][trial_name]\n",
    "        else: \n",
    "            segments = subjects[subject_name][trial_name]['segments']            \n",
    "        \n",
    "        segment_time = sum([  segments[i][1] - segments[i][0] for i in range(len(segments))])*subjects[subject_name]['seconds_per_frame']\n",
    "        \n",
    "        print(f\"    Subject:{subject_name} Trial Index:{trial_name} Length: {trial_length} Segment Length:{segment_time}  {segments} Headers:{plot_headers}\")\n",
    "        \n",
    "        for plotting_variable in plot_data_trial:\n",
    "            assert len(plot_data_trial[plotting_variable].shape) == 2, \"Data should be 2D\"\n",
    "\n",
    "            time_normalized_series = [time_normalization(plot_data_trial[plotting_variable][segment[0]:segment[1]]) for segment in segments] \n",
    "            \n",
    "            if plotting_variable not in plot_data:\n",
    "                plot_data[plotting_variable] = []\n",
    "            plot_data[plotting_variable].extend(time_normalized_series)\n",
    "\n",
    "    if len(plot_data) == 0: # Tracks are empty  \n",
    "        continue\n",
    "    \n",
    "    for plotting_variable in plot_data: \n",
    "        plot_data[plotting_variable] = np.array(plot_data[plotting_variable]).transpose((2,0,1))\n",
    "\n",
    "        print(subject_name)\n",
    "\n",
    "        fig_title = f\"{plotting_variable} for Subject:{PPE_Subjects[subject_name]} MCS:{mcs_scores[subject_name]}\"\n",
    "        fig = plot_simulation_data(plot_headers, plot_data[plotting_variable], fig_title, visualize=subject_name in manual_segments   ,data_type=plotting_variable)\n",
    "        plotly.io.write_image(fig, f'pdfs/{PPE_Subjects[subject_name]}_{plotting_variable}.pdf', format='pdf')\n",
    "\n",
    "\n",
    "        if not np.isnan(plot_data[plotting_variable]).any(): \n",
    "            aggregate_data[plotting_variable]['mean'] += plot_data[plotting_variable].sum(axis=1)\n",
    "            aggregate_data[plotting_variable]['std'] += (plot_data[plotting_variable]**2).sum(axis=1)\n",
    "            \n",
    "            mcs_score = mcs_scores[subject_name]\n",
    "\n",
    "            if plotting_variable not in mcs_aggregate_data[mcs_score]: \n",
    "                mcs_aggregate_data[mcs_score][plotting_variable] = {}\n",
    "                mcs_aggregate_data[mcs_score][plotting_variable]['mean'] = np.zeros((len(plot_names_mapping),101))\n",
    "                mcs_aggregate_data[mcs_score][plotting_variable]['std'] = np.zeros((len(plot_names_mapping),101))\n",
    "                mcs_aggregate_data[mcs_score][plotting_variable]['list'] = np.zeros((0,len(plot_names_mapping),101))\n",
    "                mcs_aggregate_data[mcs_score][plotting_variable]['ppe_names'] = []\n",
    "                mcs_aggregate_data[mcs_score][plotting_variable]['total_trials'] = 0\n",
    "            \n",
    "            mcs_aggregate_data[mcs_score][plotting_variable]['mean'] += plot_data[plotting_variable].sum(axis=1)\n",
    "            mcs_aggregate_data[mcs_score][plotting_variable]['std'] += (plot_data[plotting_variable]**2).sum(axis=1)\n",
    "\n",
    "            mcs_aggregate_data[mcs_score][plotting_variable]['list'] = np.concatenate([ mcs_aggregate_data[mcs_score][plotting_variable]['list'],\n",
    "                                                                                       np.transpose(plot_data[plotting_variable], (1,0,2)   ) ])\n",
    "            \n",
    "            mcs_aggregate_data[mcs_score][plotting_variable]['ppe_names'].extend([PPE_Subjects[subject_name]]*plot_data[plotting_variable].shape[1])\n",
    "            mcs_aggregate_data[mcs_score][plotting_variable]['total_trials'] += plot_data[plotting_variable].shape[1]\n",
    "            \n",
    "            \n",
    "    total_trials += plot_data[plotting_variable].shape[1]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "for k in aggregate_data:\n",
    "    aggregate_data[k]['mean'] /= total_trials\n",
    "    aggregate_data[k]['std'] = np.sqrt(aggregate_data[k]['std']/total_trials - aggregate_data[k]['mean']**2)\n",
    "\n",
    "    # break\n",
    "\n",
    "for mcs_score in mcs_aggregate_data:\n",
    "    for plotting_variable in mcs_aggregate_data[mcs_score]: \n",
    "        mcs_aggregate_data[mcs_score][plotting_variable]['mean'] /= mcs_aggregate_data[mcs_score][plotting_variable]['total_trials']\n",
    "        mcs_aggregate_data[mcs_score][plotting_variable]['std'] = np.sqrt(mcs_aggregate_data[mcs_score][plotting_variable]['std']/mcs_aggregate_data[mcs_score][plotting_variable]['total_trials'] - mcs_aggregate_data[mcs_score][plotting_variable]['mean']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Aggregate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_distribution(headers,plot_data_mean,plot_data_std,title_text=\"Plot Data\",data_type=\"kinematics\"): \n",
    "    \n",
    "    # assert plot_data.shape[-1] == 101, \"Length of data should be 101\"\n",
    "    num_rows = int(math.ceil(len(headers)/3))\n",
    "    num_cols = 3\n",
    "    # Create 4x4 subplots (we'll only use 14 of them)\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[plot_names_mapping[header] for header in headers])\n",
    "\n",
    "    # Colors for left and right sides\n",
    "    colors = {'left': 'blue', 'right': 'red'}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i, header in enumerate(headers):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "        \n",
    "        if i >= len(headers): \n",
    "            break\n",
    "\n",
    "        title = plot_names_mapping[header]\n",
    "\n",
    "        # Plot every kinematics data\n",
    "        x = np.linspace(0,1,num=plot_data_mean[i].shape[-1])\n",
    "\n",
    "    \n",
    "        fig.add_trace(go.Scatter(x=x, y=plot_data_mean[i], showlegend=False, name=f'{title}'), row=row, col=col)\n",
    "        fig.add_trace(go.Scatter(x=list(x) + list(x)[::-1], \n",
    "                                    y=list(plot_data_mean[i] + np.array(plot_data_std[i])) + list(np.array(plot_data_mean[i]) - np.array(plot_data_std[i]))[::-1] ,\n",
    "                                        mode='lines', line=dict(width=0), name=f'{title} Bounds', showlegend=False, fill='toself',hoverinfo=\"skip\",),\n",
    "        row=row, col=col)\n",
    "\n",
    "        # Update y-axis label\n",
    "        if data_type == 'kinematics':\n",
    "            fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text='Nm', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text='% SQT Cycle (Seconds)', row=row, col=col)\n",
    "\n",
    "    \n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=2000, width=1000,\n",
    "                        showlegend=False,  title_x=0.5,\n",
    "                        title_text=title_text,\n",
    "                        font_family=\"Times New Roman\",\n",
    "                        font_color=\"black\",\n",
    "                        title_font_family=\"Times New Roman\",\n",
    "                        title_font_color=\"black\")\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "for k in aggregate_data:\n",
    "    fig = plot_data_distribution(plot_headers, aggregate_data[k]['mean'],aggregate_data[k]['std'], f\"Aggregate {k} Data\",data_type=k)\n",
    "    plotly.io.write_image(fig, f'pdfs/all_subject_{k}.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Per MCS data\n",
    "\n",
    "def plot_mcs_distribution(headers,mcs_aggregate_data,title_text=\"Plot Data\",data_type=\"kinematics\"): \n",
    "    \n",
    "    # assert plot_data.shape[-1] == 101, \"Length of data should be 101\"\n",
    "    num_rows = int(math.ceil(len(headers)/3))\n",
    "    num_cols = 3\n",
    "    # Create 4x4 subplots (we'll only use 14 of them)\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[plot_names_mapping[header] for header in headers])\n",
    "\n",
    "    # Colors for left and right sides\n",
    "    colors = {2: 'rgba(255, 0, 0, 0.2)', 3: 'rgba(0, 0, 255, 0.2)' , 4: 'rgba(0, 255, 0, 0.2)'}\n",
    "    colors_mean = {2: 'rgba(255, 0, 0, 1.0)', 3: 'rgba(0, 0, 255, 1.0)' , 4: 'rgba(0, 255, 0, 1.0)'}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i, header in enumerate(headers):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "        \n",
    "        if i >= len(headers): \n",
    "            break\n",
    "\n",
    "        title = plot_names_mapping[header]\n",
    "\n",
    "        # Plot every kinematics data\n",
    "        x = None\n",
    "\n",
    "        for mcs_score in mcs_aggregate_data: \n",
    "            plot_data_mean = mcs_aggregate_data[mcs_score][data_type]['mean']\n",
    "            plot_data_std = mcs_aggregate_data[mcs_score][data_type]['std']\n",
    "            # print(plot_data_mean.shape)\n",
    "            if x is None: \n",
    "                x = np.linspace(0,1,num=plot_data_mean[i].shape[-1])                            \n",
    "\n",
    "            fig.add_trace(go.Scatter(x=x, y=plot_data_mean[i], showlegend = (i==len(headers)-1), \n",
    "                                    name=f'MCS:{mcs_score}',line=dict(color=colors_mean[mcs_score])), row=row, col=col)\n",
    "            fig.add_trace(go.Scatter(x=list(x) + list(x)[::-1], \n",
    "                                        y=list(plot_data_mean[i] + np.array(plot_data_std[i]/2)) + list(np.array(plot_data_mean[i]) - np.array(plot_data_std[i]/2))[::-1] ,\n",
    "                                            mode='lines', line=dict(width=0), name=f'MCS:{mcs_score} Bounds', showlegend=False, fill='toself',hoverinfo=\"skip\",fillcolor=colors[mcs_score]),\n",
    "            row=row, col=col)\n",
    "\n",
    "        # Update y-axis label\n",
    "        if data_type == 'kinematics':\n",
    "            fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text='Nm', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text='% SQT Cycle (Seconds)', row=row, col=col)\n",
    "\n",
    "    \n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=2000, width=1000,\n",
    "                        showlegend=True,  title_x=0.5,\n",
    "                        title_text=title_text,\n",
    "                        font_family=\"Times New Roman\",\n",
    "                        font_color=\"black\",\n",
    "                        title_font_family=\"Times New Roman\",\n",
    "                        title_font_color=\"black\")\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "for k in ['kinematics','kinetics']:\n",
    "    fig = plot_mcs_distribution(plot_headers, mcs_aggregate_data, f\"MCS {k} Distributions\",data_type=k)\n",
    "    plotly.io.write_image(fig, f'pdfs/mcs_subject_{k}_distribution.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all mcs lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Per MCS data\n",
    "\n",
    "def plot_mcs_data(headers,mcs_aggregate_data,title_text=\"Plot Data\",data_type=\"kinematics\"): \n",
    "    \n",
    "    # assert plot_data.shape[-1] == 101, \"Length of data should be 101\"\n",
    "    num_rows = int(math.ceil(len(headers)/3))\n",
    "    num_cols = 3\n",
    "    # Create 4x4 subplots (we'll only use 14 of them)\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[plot_names_mapping[header] for header in headers])\n",
    "\n",
    "    # Colors for left and right sides\n",
    "    colors = {2: 'rgba(255, 0, 0, 0.2)', 3: 'rgba(0, 0, 255, 0.2)' , 4: 'rgba(0, 255, 0, 0.2)'}\n",
    "    colors_mean = {2: 'rgba(255, 0, 0, 1.0)', 3: 'rgba(0, 0, 255, 1.0)' , 4: 'rgba(0, 255, 0, 1.0)'}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i, header in enumerate(headers):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "        \n",
    "        if i >= len(headers): \n",
    "            break\n",
    "\n",
    "        title = plot_names_mapping[header]\n",
    "\n",
    "        # Plot every kinematics data\n",
    "        x = None\n",
    "\n",
    "        for mcs_score in mcs_aggregate_data: \n",
    "            for y_ind, y in enumerate(mcs_aggregate_data[mcs_score][data_type]['list']):\n",
    "\n",
    "                if x is None: \n",
    "                    x = np.linspace(0,1,num=y.shape[-1])                            \n",
    "\n",
    "                show_lengend = (i==len(headers)-1) and y_ind==0 \n",
    "                if show_lengend:\n",
    "                    plot_name = f\"MCS:{mcs_score}\"\n",
    "                else: \n",
    "                    plot_name = f'{mcs_aggregate_data[mcs_score][data_type][\"ppe_names\"][y_ind]}'\n",
    "\n",
    "                fig.add_trace(go.Scatter(x=x, y=y[i], showlegend=show_lengend, \n",
    "                                        name=plot_name,line=dict(color=colors_mean[mcs_score])), row=row, col=col)\n",
    "\n",
    "        # Update y-axis label\n",
    "        if data_type == 'kinematics':\n",
    "            fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text='Nm', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='deg', row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text='% SQT Cycle (Seconds)', row=row, col=col)\n",
    "\n",
    "    \n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=2000, width=1000,\n",
    "                        showlegend=True,  title_x=0.5,\n",
    "                        title_text=title_text,\n",
    "                        font_family=\"Times New Roman\",\n",
    "                        font_color=\"black\",\n",
    "                        title_font_family=\"Times New Roman\",\n",
    "                        title_font_color=\"black\")\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "for k in ['kinematics','kinetics']:\n",
    "    fig = plot_mcs_data(plot_headers, mcs_aggregate_data, f\"MCS {k} Data\",data_type=k)\n",
    "    plotly.io.write_image(fig, f'pdfs/mcs_subject_{k}.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfMerger\n",
    "import glob\n",
    "\n",
    "pdfs = os.listdir(\"pdfs\")\n",
    "pdfs = sorted(pdfs)\n",
    "\n",
    "pdfs.remove(\"all_subject_kinetics.pdf\")\n",
    "pdfs.insert(0,\"all_subject_kinetics.pdf\")\n",
    "\n",
    "pdfs.remove(\"all_subject_kinematics.pdf\")\n",
    "pdfs.insert(0,\"all_subject_kinematics.pdf\")\n",
    "\n",
    "pdfs.remove(\"mcs_subject_kinetics_distribution.pdf\")\n",
    "pdfs.insert(0,\"mcs_subject_kinetics_distribution.pdf\")\n",
    "\n",
    "pdfs.remove(\"mcs_subject_kinematics_distribution.pdf\")\n",
    "pdfs.insert(0,\"mcs_subject_kinematics_distribution.pdf\")\n",
    "\n",
    "pdfs.remove(\"mcs_subject_kinetics.pdf\")\n",
    "pdfs.insert(0,\"mcs_subject_kinetics.pdf\")\n",
    "\n",
    "pdfs.remove(\"mcs_subject_kinematics.pdf\")\n",
    "pdfs.insert(0,\"mcs_subject_kinematics.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merger = PdfMerger()\n",
    "\n",
    "for pdf in pdfs:\n",
    "    merger.append(os.path.join(\"pdfs\",pdf))\n",
    "\n",
    "merger.write(\"MCS-SQT.pdf\")\n",
    "merger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mcs_score in mcs_aggregate_data:\n",
    "    data_type = 'kinematics'\n",
    "    subjects_set = set(mcs_aggregate_data[mcs_score][data_type][\"ppe_names\"])\n",
    "    print(mcs_score, subjects_set, len(mcs_aggregate_data[mcs_score][data_type][\"ppe_names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
